{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "beca8ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: Baden-Wurttemberg, URL: https://www.4icu.org/de/baden-wurttemberg/\n",
      "state: Bavaria, URL: https://www.4icu.org/de/bavaria/\n",
      "state: Berlin, URL: https://www.4icu.org/de/berlin/\n",
      "state: Brandenburg, URL: https://www.4icu.org/de/brandenburg/\n",
      "state: Bremen, URL: https://www.4icu.org/de/bremen/\n",
      "state: Hamburg, URL: https://www.4icu.org/de/hamburg/\n",
      "state: Hesse, URL: https://www.4icu.org/de/hesse/\n",
      "state: Lower Saxony, URL: https://www.4icu.org/de/lower-saxony/\n",
      "state: Mecklenburg-Vorpommern, URL: https://www.4icu.org/de/mecklenburg-vorpommern/\n",
      "state: North Rhine-Westphalia, URL: https://www.4icu.org/de/north-rhine-westphalia/\n",
      "state: Rhineland-Palatinate, URL: https://www.4icu.org/de/rhineland-palatinate/\n",
      "state: Saarland, URL: https://www.4icu.org/de/saarland/\n",
      "state: Saxony, URL: https://www.4icu.org/de/saxony/\n",
      "state: Saxony-Anhalt, URL: https://www.4icu.org/de/saxony-anhalt/\n",
      "state: Schleswig-Holstein, URL: https://www.4icu.org/de/schleswig-holstein/\n",
      "state: Thuringia, URL: https://www.4icu.org/de/thuringia/\n",
      "Total 16 states\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_university_data(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Check if the request was successful\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    universities = []\n",
    "    \n",
    "    # Adjust these selectors based on the actual HTML structure of the page\n",
    "    university_rows = soup.find_all('div', class_='university-entry')  # Example class name\n",
    "    \n",
    "    if not university_rows:\n",
    "        print(f\"No university data found at {url}\")\n",
    "        return universities\n",
    "    \n",
    "    for university_row in university_rows:\n",
    "        university_data = {}\n",
    "        \n",
    "        # Extract university name\n",
    "        name = university_row.find('h3').text.strip()\n",
    "        university_data['name'] = name\n",
    "        \n",
    "        # Extract university logo URL\n",
    "        logo = university_row.find('img')\n",
    "        if logo:\n",
    "            university_data['logoSrc'] = logo.get('src', '').strip()\n",
    "        else:\n",
    "            university_data['logoSrc'] = ''\n",
    "        \n",
    "        # Extract university type (example, adapt as needed)\n",
    "        type = university_row.find('span', class_='type')\n",
    "        university_data['type'] = type.text.strip() if type else 'Unknown'\n",
    "        \n",
    "        # Extract founded year (example, adapt as needed)\n",
    "        founded_year = university_row.find('span', class_='founded')\n",
    "        university_data['establishedYear'] = founded_year.text.strip() if founded_year else 'Unknown'\n",
    "        \n",
    "        # Extract location details\n",
    "        location_text = university_row.find('small').text.strip()\n",
    "        location_parts = location_text.split(', ')\n",
    "        university_data['location'] = {\n",
    "            'country': 'Germany',\n",
    "            'state': location_parts[0] if len(location_parts) > 1 else 'Unknown',\n",
    "            'city': location_parts[-1] if len(location_parts) > 1 else location_parts[0]\n",
    "        }\n",
    "        \n",
    "        # Extract social media URLs\n",
    "        social_media_urls = {\n",
    "            'facebook': '',\n",
    "            'twitter': '',\n",
    "            'instagram': '',\n",
    "            'officialWebsite': '',\n",
    "            'linkedin': '',\n",
    "            'youtube': ''\n",
    "        }\n",
    "        \n",
    "        social_media_links = university_row.find_all('a', class_='social-link')\n",
    "        for link in social_media_links:\n",
    "            href = link.get('href', '')\n",
    "            if 'facebook.com' in href:\n",
    "                social_media_urls['facebook'] = href\n",
    "            elif 'twitter.com' in href:\n",
    "                social_media_urls['twitter'] = href\n",
    "            elif 'instagram.com' in href:\n",
    "                social_media_urls['instagram'] = href\n",
    "            elif 'linkedin.com' in href:\n",
    "                social_media_urls['linkedin'] = href\n",
    "            elif 'youtube.com' in href:\n",
    "                social_media_urls['youtube'] = href\n",
    "            else:\n",
    "                social_media_urls['officialWebsite'] = href\n",
    "        \n",
    "        university_data['contact'] = social_media_urls\n",
    "        \n",
    "        universities.append(university_data)\n",
    "    \n",
    "    return universities\n",
    "\n",
    "\n",
    "mainUrl = 'https://www.4icu.org/de/universities/'\n",
    "response = requests.get(mainUrl)\n",
    "response.encoding = 'utf-8'\n",
    "soup = BeautifulSoup(response.text,'lxml')\n",
    "all_universities = []\n",
    "    \n",
    "tables = soup.find('table', class_ = 'table')\n",
    "stateLinks = []\n",
    "baseUrl = 'https://www.4icu.org'\n",
    "\n",
    "for aTag in tables.find_all('a', href=True):\n",
    "    stateName = aTag.text.strip()\n",
    "    stateUrl = baseUrl + aTag['href']\n",
    "    stateLinks.append({'state name':stateName,'state url':stateUrl})\n",
    "\n",
    "for state in stateLinks:\n",
    "    print(f\"state: {state['state name']}, URL: {state['state url']}\")\n",
    "\n",
    "print(f\"Total {len(stateLinks)} states\")\n",
    "\n",
    "# Print data as JSON\n",
    "print(json.dumps(all_universities, ensure_ascii=False, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef317c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stateUniversities = []\n",
    "for state in stateLinks:\n",
    "    url = state['state url']\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    uni_table = soup.find('tbody')\n",
    "    universityLinks = []\n",
    "    \n",
    "    for aTag in uni_table.find_all('a', href=True):\n",
    "        if aTag['href'] == '/about/add.htm':\n",
    "            continue\n",
    "        uniUrl = baseUrl + aTag['href']\n",
    "        universityLinks.append(uniUrl)\n",
    "    stateUniversities.append({'state':state['state name'], 'universityLinks':universityLinks})\n",
    "\n",
    "import json\n",
    "universities = []\n",
    "for university in stateUniversities:\n",
    "    stateName = university['state']\n",
    "    for uniUrl in university['universityLinks']:\n",
    "        response = requests.get(uniUrl)\n",
    "        response.encoding = 'utf-8'\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        logo = soup.find('img', attrs={\"itemprop\":\"logo\"})\n",
    "        uniName = soup.find('h1', attrs={\"itemprop\":\"name\"})\n",
    "        cityName = soup.find('span', attrs={\"itemprop\":\"addressLocality\"})\n",
    "        type = soup.find('p' ,class_ = 'lead').find('strong')\n",
    "        foundedYear = soup.find('table', class_='table borderless').find('span', attrs={\"itemprop\":\"foundingDate\"})\n",
    "        socialLinks = soup.find('div', attrs={\"id\":\"social-media\"}).find_all('a',attrs={\"itemprop\":\"sameAs\"})\n",
    "        uniLink = soup.find('a', attrs={\"itemprop\":\"url\"})\n",
    "        def determine_media_type(url):\n",
    "            if 'facebook.com' in url:\n",
    "                return 'facebook'\n",
    "            elif 'instagram.com' in url:\n",
    "                return 'instagram'\n",
    "            elif 'twitter.com' in url:\n",
    "                return 'twitter'\n",
    "            elif 'linkedin.com' in url:\n",
    "                return 'linkedin'\n",
    "            elif 'youtube.com' in url:\n",
    "                return 'youtube'\n",
    "            else:\n",
    "                return 'unknown'\n",
    "        socialUrls = []\n",
    "        for url in socialLinks:\n",
    "            socialUrls.append({'media': determine_media_type(url['href']),'link':url['href']})\n",
    "        social_media_map = {\n",
    "        'facebook': '',\n",
    "        'twitter': '',\n",
    "        'instagram': '',\n",
    "        'linkedin': '',\n",
    "        'youtube': ''\n",
    "        }\n",
    "        for social_url in socialUrls:\n",
    "            url = social_url['link']\n",
    "            if 'facebook.com' in url:\n",
    "                social_media_map['facebook'] = url\n",
    "            elif 'twitter.com' in url:\n",
    "                social_media_map['twitter'] = url\n",
    "            elif 'instagram.com' in url:\n",
    "                social_media_map['instagram'] = url\n",
    "            elif 'linkedin.com' in url:\n",
    "                social_media_map['linkedin'] = url\n",
    "            elif 'youtube.com' in url:\n",
    "                social_media_map['youtube'] = url\n",
    "        entry = {\n",
    "            \"name\":uniName.text.strip(),\n",
    "            \"location\":{\n",
    "                \"country\":\"Germany\",\n",
    "                \"state\":stateName,\n",
    "                \"city\":cityName.text.strip()\n",
    "            },\n",
    "            \"logoSrc\":logo['src'],\n",
    "            \"type\":type.text.strip(),\n",
    "            \"establishedYear\":foundedYear.text.strip(),\n",
    "            \"contact\": {\n",
    "     \"facebook\": social_media_map['facebook'],\n",
    "    \"twitter\": social_media_map['twitter'],\n",
    "    \"instagram\": social_media_map['instagram'],\n",
    "    \"officialWebsite\": str(uniLink['href']),\n",
    "    \"linkedin\": social_media_map['linkedin'],\n",
    "    \"youtube\": social_media_map['youtube']\n",
    "            }\n",
    "        }\n",
    "        universities.append(json.dumps(entry, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763c68c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
